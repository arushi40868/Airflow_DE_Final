# ğŸŒ€ Airflow Data Engineering Pipeline

This repository contains an **Apache Airflow pipeline** designed to **ingest, transform, and analyze** multiple datasets in a containerized environment. The project demonstrates end-to-end **data pipeline orchestration**, **parallel processing**, and **database integration** using **PostgreSQL** â€” all deployed via **Docker** and managed through **Airflow DAGs**.

---

## ğŸš€ Project Overview

This pipeline automates the following workflow:

1. **Data Ingestion**  
   - Fetches two related datasets (CSV format).  
   - Datasets are stored locally within the container under `/opt/airflow/data`.

2. **Data Transformation**  
   - Cleans and standardizes columns (e.g., handling nulls, formatting strings, renaming columns).  
   - Aggregates and filters data for meaningful insights.  
   - TaskGroups are used to organize transformation steps logically.

3. **Data Loading (ETL)**  
   - Merges the transformed datasets.  
   - Loads the final result into a **PostgreSQL** database.  
   - Uses Airflowâ€™s `PostgresHook` for database connectivity.

4. **Analysis / Output**  
   - Reads the cleaned data from PostgreSQL.  
   - Performs a simple analysis â€” for example, generating summary statistics or a visualization.  
   - Saves results to `/opt/airflow/output`.

5. **Cleanup**  
   - Deletes any intermediate CSVs or temporary files created during execution.

---

## âš™ï¸ Architecture Diagram

```mermaid
graph TD
    A[Start DAG] --> B[Fetch Datasets]
    B --> C[Transform Dataset 1]
    B --> D[Transform Dataset 2]
    C --> E[Merge Datasets]
    D --> E
    E --> F[Load to PostgreSQL]
    F --> G[Perform Analysis]
    G --> H[Clean Up Intermediate Files]
    H --> I[End DAG]
```

---

## ğŸ§© Tech Stack

- **Apache Airflow** â€“ Orchestration
- **PostgreSQL** â€“ Data storage
- **Docker + Dev Containers** â€“ Reproducible environment
- **Python (Pandas, Faker, Psycopg2)** â€“ Data transformation & analysis

---

## ğŸ—‚ Repository Structure

```
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ pipeline.py           # Main Airflow DAG
â”œâ”€â”€ data/                     # Raw and transformed datasets
â”œâ”€â”€ Dockerfile                # Container setup
â”œâ”€â”€ devcontainer.json         # VS Code remote development config
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ screenshots/              # DAG run + Graph view screenshots
â”œâ”€â”€ README.md                 # Documentation (this file)
â””â”€â”€ output/                   # Final results or visualization
```

---

## ğŸ§° Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/arushi40868/Airflow_DE_Final.git
cd Airflow_DE_Final
```

### 2. Build and start the containers
```bash
docker-compose up --build
```

### 3. Access the Airflow UI
Visit **http://localhost:8080** and log in using:
```
Username: airflow
Password: airflow
```

### 4. Trigger the DAG
- Enable the DAG named `pipeline` in the Airflow UI.  
- Click **Trigger DAG** to run the workflow manually or wait for its scheduled run.

---

## ğŸ“Š Results & Analysis

Once the DAG completes:
- The final merged data table is stored in **PostgreSQL** under the target schema/table.
- The output folder contains analysis results such as:
  - Aggregated metrics  
  - Summary statistics  
  - Visualization (if generated)

---

## ğŸ“¸ Screenshots

| DAG Status | Graph View |
|-------------|-------------|
| ![Successful DAG Execution](successful_run.png) | ![Graph View](pipeline.png) |

---

## ğŸ§¼ Cleanup

After a successful run, temporary datasets are automatically deleted.  
If needed, you can manually clear all intermediate files with:
```bash
docker exec -it airflow-webserver rm -rf /opt/airflow/data/temp/
```

---

## ğŸ§  Key Learnings

- Building modular ETL workflows using **TaskGroups**
- Handling dependencies and retries in Airflow
- Loading data into relational databases with `PostgresHook`
- Containerizing Airflow pipelines for reproducibility
- Visualizing DAGs for process transparency

---

## ğŸ‘©â€ğŸ’» Author

**Arushi Singh**  
Business Intelligence Engineer | Data Science Enthusiast  
ğŸ“ [GitHub](https://github.com/arushi40868) â€¢ [LinkedIn](https://www.linkedin.com/in/arushi-singh40868/)
